{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the experiments, you need to download the dataset generated by SUMO, which is accessible at [[training set](https://drive.google.com/file/d/1GM3CMnkQcRPQNsgBjqHzDqwB8zLJoNaC/view?usp=share_link)] and [[validation set](https://drive.google.com/file/d/1ar6zcAqJJJCe18O6XlJ6ja9dFKwcgf52/view?usp=share_link)]. Then please run the following command to create a folder named `csv` and move the downloaded files `train_pre.zip` and `val_pre.zip` into this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the dataset, you can use the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q csv/train_pre.zip -d csv\n",
    "!unzip -q csv/val_pre.zip -d csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GraphConv as GNNConv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import CarDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_folder = \"csv/train_pre\"\n",
    "val_folder = \"csv/val_pre\"\n",
    "exp_id = \"sumo_test\"\n",
    "model_path = f\"trained_params/{exp_id}\"\n",
    "mlp = False\n",
    "collision_penalty = False\n",
    "lr = 1e-3\n",
    "n_epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CarDataset(preprocess_folder=train_folder, mlp=False, mpc_aug=True)\n",
    "val_dataset = CarDataset(preprocess_folder=val_folder, mlp=False, mpc_aug=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition & instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_mtl_gnn(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(21)\n",
    "        self.conv1 = GNNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GNNConv(hidden_channels, hidden_channels)\n",
    "        self.linear1 = nn.Linear(6, 64)\n",
    "        self.linear2 = nn.Linear(64, hidden_channels)\n",
    "        self.linear3 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.linear4 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.linear5 = nn.Linear(hidden_channels, 30*2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.linear1(x).relu()\n",
    "        x = self.linear2(x).relu()\n",
    "        x = self.linear3(x).relu() + x\n",
    "        x = self.linear4(x).relu() + x\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.linear5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN_mtl_gnn(\n",
      "  (conv1): GraphConv(128, 128)\n",
      "  (conv2): GraphConv(128, 128)\n",
      "  (linear1): Linear(in_features=6, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear5): Linear(in_features=128, out_features=60, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GNN_mtl_gnn(hidden_channels=128)\n",
    "print(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_back(yaw):\n",
    "    \"\"\"\n",
    "    Rotate back from the local coordinate system to the global coordinate system. \n",
    "    \"\"\"\n",
    "    rotation = np.array([[np.cos(-np.pi/2+yaw), -np.sin(-np.pi/2+yaw)],[np.sin(-np.pi/2+yaw), np.cos(-np.pi/2+yaw)]])\n",
    "    rotation = torch.tensor(rotation).float()\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, collision_penalty=False):\n",
    "    \"\"\" Performs an epoch of model training.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): Model to be trained.\n",
    "    device (torch.Device): Device used for training.\n",
    "    data_loader (torch.utils.data.DataLoader): Data loader containing all batches.\n",
    "    optimizer (torch.optim.Optimizer): Optimizer used to update model.\n",
    "    collision_penalty (bool): set it to True if you want to use collision penalty.\n",
    "\n",
    "    Returns:\n",
    "    float: Total loss for epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    dist_threshold = 4\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x[:,[0, 1, 3, 4, 5, 6]], batch.edge_index)   # [x, y, yaw, 3-bit intention]\n",
    "        out = out.reshape(-1, 30, 2)\n",
    "        out = out.permute(0, 2, 1)    # [v, 2, pred]\n",
    "        yaw = batch.x[:, 3].detach().cpu().numpy()\n",
    "        rotations = torch.stack([rotation_matrix_back(yaw[i])  for i in range(batch.x.shape[0])]).to(out.device)\n",
    "        out = torch.bmm(rotations, out).permute(0, 2, 1)       # [v, pred, 2]\n",
    "        out += batch.x[:,[0, 1]].unsqueeze(1)\n",
    "        gt = batch.y.reshape(-1, 30, 6)[:,:,[0, 1]]\n",
    "        error = ((gt-out).square().sum(-1)).sum(-1)\n",
    "        loss = (batch.weights * error).nanmean()\n",
    "        \n",
    "        if collision_penalty:\n",
    "            mask = (batch.edge_index[0, :] < batch.edge_index[1, :])\n",
    "            _edge = batch.edge_index[:, mask].T   # [edge',2]\n",
    "            dist = torch.linalg.norm(out[_edge[:, 0]] - out[_edge[:, 1]], dim=-1)\n",
    "            dist = dist_threshold - dist[dist < dist_threshold]\n",
    "            _collision_penalty = dist.square().mean()\n",
    "            loss += _collision_penalty * 20\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, data_loader):\n",
    "    \"\"\" Performs the evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    model (nn.Module): Model to be trained.\n",
    "    device (torch.Device): Device used for training.\n",
    "    data_loader (torch.utils.data.DataLoader): Data loader containing all batches.\n",
    "\n",
    "    Returns:\n",
    "    list of evaluation metrics (including ADE, FDE, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    dist_threshold = 4\n",
    "    mr_threshold = 4\n",
    "    model.eval()\n",
    "    ade, fde = [], []\n",
    "    n_edge, n_collision = [], []\n",
    "    val_losses, collision_penalties = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x[:,[0, 1, 3, 4, 5, 6]], batch.edge_index)\n",
    "            out = out.reshape(-1, 30, 2)\n",
    "            out = out.permute(0, 2, 1)\n",
    "            yaw = batch.x[:, 3].detach().cpu().numpy()\n",
    "            rotations = torch.stack([rotation_matrix_back(yaw[i])  for i in range(batch.x.shape[0])]).to(out.device)\n",
    "            out = torch.bmm(rotations, out).permute(0, 2, 1)       # [v, pred, 2]\n",
    "            out += batch.x[:,[0, 1]].unsqueeze(1)\n",
    "            \n",
    "            gt = batch.y.reshape(-1, 30, 6)[:, :, [0, 1]]\n",
    "            _error = (gt-out).square().sum(-1)\n",
    "            error = _error.clone() ** 0.5\n",
    "            _error = _error.sum(-1)\n",
    "            val_loss = (batch.weights * _error).nanmean()\n",
    "            val_losses.append(val_loss)\n",
    "            fde.append(error[:,-1])\n",
    "            ade.append(error.mean(dim=-1))\n",
    "\n",
    "            mask = (batch.edge_index[0,:] < batch.edge_index[1,:])\n",
    "            _edge = batch.edge_index[:, mask].T   # [edge',2]\n",
    "            dist = torch.linalg.norm(out[_edge[:,0]] - out[_edge[:,1]], dim=-1)\n",
    "            collision_penalty = dist_threshold - dist[dist < dist_threshold]\n",
    "            collision_penalty = collision_penalty.square().mean() * 20\n",
    "            collision_penalties.append(collision_penalty)\n",
    "\n",
    "            dist = torch.min(dist, dim=-1)[0]\n",
    "            n_edge.append(len(dist))\n",
    "            n_collision.append((dist < 2).sum().item())\n",
    "    \n",
    "    ade = torch.cat(ade).mean()\n",
    "    fde = torch.cat(fde)\n",
    "    mr = ((fde > mr_threshold).sum() / len(fde)).item()\n",
    "    fde = fde.mean()\n",
    "    collision_rate = sum(n_collision) / sum(n_edge)\n",
    "    collision_penalties = torch.tensor(collision_penalties).mean()\n",
    "    val_losses = torch.tensor(val_losses).mean()\n",
    "    \n",
    "    return ade.item(), fde.item(), mr, collision_rate, val_losses.item(), collision_penalties.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:01<03:44,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 204191.59598214287, ADE: 17.99057388305664, FDE: 25.204317092895508, MR: 0.9461342096328735, CR:0.033681462140992165,             Val_loss: 210975.859375, CP: nan, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:09<01:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 14771.683837890625, ADE: 4.887154579162598, FDE: 8.52444839477539, MR: 0.7570093274116516, CR:0.4651436031331593,             Val_loss: 19282.283203125, CP: 93.7400894165039, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [00:16<01:38,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 5518.316162109375, ADE: 3.237579584121704, FDE: 5.9307074546813965, MR: 0.5901443958282471, CR:0.574934725848564,             Val_loss: 9008.125, CP: 102.0328369140625, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 31/150 [00:24<01:37,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss: 3577.1335013253347, ADE: 2.703300952911377, FDE: 4.948358058929443, MR: 0.46745961904525757, CR:0.6518276762402089,             Val_loss: 6970.52294921875, CP: 114.27143096923828, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [00:30<01:22,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss: 2800.9671456473216, ADE: 2.601576805114746, FDE: 4.953203201293945, MR: 0.4700084924697876, CR:0.7093994778067885,             Val_loss: 6769.8330078125, CP: 120.59954071044922, lr: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [00:38<01:18,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 2409.840105329241, ADE: 2.693805694580078, FDE: 5.066558361053467, MR: 0.46661001443862915, CR:0.7515665796344647,             Val_loss: 7231.583984375, CP: 115.84384155273438, lr: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 61/150 [00:45<01:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss: 1868.4940708705358, ADE: 2.571370840072632, FDE: 4.882014274597168, MR: 0.43857261538505554, CR:0.7580939947780679,             Val_loss: 6846.5830078125, CP: 119.41574096679688, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 71/150 [00:53<01:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train Loss: 1610.8249773297991, ADE: 2.5238358974456787, FDE: 4.843796253204346, MR: 0.44621917605400085, CR:0.7941253263707572,             Val_loss: 7047.064453125, CP: 128.0289764404297, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [01:01<00:58,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train Loss: 1448.5355224609375, ADE: 2.4165570735931396, FDE: 4.650563716888428, MR: 0.4088360071182251, CR:0.7787206266318538,             Val_loss: 6962.2314453125, CP: 129.2513427734375, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 91/150 [01:08<00:50,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss: 1310.5351867675781, ADE: 2.413524866104126, FDE: 4.625000476837158, MR: 0.4056074619293213, CR:0.8039164490861619,             Val_loss: 7094.41259765625, CP: 128.8695068359375, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [01:16<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss: 1067.4303131103516, ADE: 2.3872785568237305, FDE: 4.655385494232178, MR: 0.4093457758426666, CR:0.7913838120104438,             Val_loss: 7174.46044921875, CP: 134.4886474609375, lr: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [01:24<00:32,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Train Loss: 1110.0423496791295, ADE: 2.421121835708618, FDE: 4.702868461608887, MR: 0.4280373752117157, CR:0.8006527415143603,             Val_loss: 7294.501953125, CP: 130.607421875, lr: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 121/150 [01:32<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Train Loss: 910.7719116210938, ADE: 2.330911159515381, FDE: 4.541915416717529, MR: 0.4079864025115967, CR:0.8169712793733681,             Val_loss: 6962.04736328125, CP: 136.26275634765625, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [01:39<00:15,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Train Loss: 848.9992937360491, ADE: 2.3191120624542236, FDE: 4.5340576171875, MR: 0.3972811996936798, CR:0.8325065274151436,             Val_loss: 6909.578125, CP: 133.60231018066406, lr: 0.001.\n",
      "New smallest FDE!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [01:47<00:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: Train Loss: 769.4565734863281, ADE: 2.387826919555664, FDE: 4.717695713043213, MR: 0.4276975095272064, CR:0.8134464751958225,             Val_loss: 7048.095703125, CP: 135.67608642578125, lr: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:54<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "min_ade = 1e6\n",
    "min_fde = 1e6\n",
    "best_epoch = 0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "record = []\n",
    "\n",
    "for epoch in tqdm(range(0, n_epoch)):\n",
    "    loss = train(model, device, train_loader, optimizer)\n",
    "    if epoch % 10 == 0:\n",
    "        ade, fde, mr, collision_rate, val_losses, collision_penalties = evaluate(model, device, val_loader)\n",
    "        record.append([ade, fde, mr, collision_rate, val_losses, collision_penalties])\n",
    "        print(f\"Epoch {epoch}: Train Loss: {loss}, ADE: {ade}, FDE: {fde}, MR: {mr}, CR:{collision_rate}, \\\n",
    "            Val_loss: {val_losses}, CP: {collision_penalties}, lr: {optimizer.param_groups[0]['lr']}.\")\n",
    "        torch.save(model.state_dict(), model_path + \\\n",
    "            f\"/model_{'mlp' if mlp else 'gnn'}_{'wp' if collision_penalty else 'np'}_{exp_id}_e3_{str(epoch).zfill(4)}.pth\")\n",
    "        if fde < min_fde:\n",
    "            min_ade, min_fde = ade, fde\n",
    "            best_epoch = epoch\n",
    "            print(\"New smallest FDE!!\")\n",
    "\n",
    "pkl_file = f\"model_gnn_{'wp' if collision_penalty else 'np'}_{exp_id}.pkl\"\n",
    "with open(f'{model_path}/{pkl_file}', 'wb') as handle:\n",
    "    pickle.dump(record, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
