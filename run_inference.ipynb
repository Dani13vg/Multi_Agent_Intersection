{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ac36a0",
   "metadata": {},
   "source": [
    "# Inference and Evaluation of the MTP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da1b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/vida/miniconda3/envs/MTP/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import CarDataset\n",
    "from utils.config import DT, OBS_LEN, PRED_LEN\n",
    "from model import GNN_mtl_gnn, GNN_mtl_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44376b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_back(yaw):\n",
    "    rot = np.array([[np.cos(-np.pi/2 + yaw), -np.sin(-np.pi/2 + yaw)],\n",
    "                    [np.sin(-np.pi/2 + yaw),  np.cos(-np.pi/2 + yaw)]],\n",
    "                   dtype=np.float32)\n",
    "    return torch.from_numpy(rot)\n",
    "\n",
    "def run_inference(weights_path, dataloader, mlp=False, device=None):\n",
    "    \"\"\"Return a DataFrame with one row per agent-step: TIMESTAMP, TRACK_ID, X, Y, yaw, speed\"\"\"\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = (GNN_mtl_mlp(128) if mlp else GNN_mtl_gnn(128)).to(device)\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    rows = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Inference\"):\n",
    "            batch = batch.to(device)\n",
    "            out   = model(batch.x[:, [0, 1, 4, 5, 6]], batch.edge_index)\n",
    "            out   = out.reshape(-1, 30, 2).permute(0, 2, 1)           # [N, 2, 30]\n",
    "\n",
    "            yaw   = batch.x[:, 3].cpu().numpy()\n",
    "            rots  = torch.stack([rotation_matrix_back(y) for y in yaw]).to(out.device)\n",
    "            out   = torch.bmm(rots, out).permute(0, 2, 1)             # [N, 30, 2]\n",
    "            out   = out + batch.x[:, [0, 1]].unsqueeze(1)             # global coords\n",
    "\n",
    "            # Gather meta-data\n",
    "            ts0 = np.zeros(out.shape[0], dtype=np.float32)            # starting time of each sample\n",
    "            ids = np.arange(out.shape[0])                    # track IDs (0, 1, 2, ...) \n",
    "            speeds= batch.x[:, 2].cpu().numpy()\n",
    "            yaws  = yaw\n",
    "\n",
    "            for i in range(out.shape[0]):              # each agent\n",
    "                # 30 future steps → timestamps\n",
    "                fut_ts = ts0[i] + np.arange(1, 31) * DT\n",
    "                xs, ys = out[i, :, 0].cpu(), out[i, :, 1].cpu()\n",
    "                for step in range(30):\n",
    "                    rows.append(dict(TIMESTAMP=fut_ts[step],\n",
    "                                     TRACK_ID = int(ids[i]),\n",
    "                                     X        = float(xs[step]),\n",
    "                                     Y        = float(ys[step]),\n",
    "                                     yaw      = float(yaws[step%len(yaws)]),\n",
    "                                     speed    = float(speeds[i])))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def visualise(df, bg_img_path, out_mp4=\"inference.mp4\",\n",
    "              interval_ms=100, max_frames=None):\n",
    "\n",
    "    # Background image\n",
    "    bg_img = plt.imread(bg_img_path)\n",
    "    # Decide world-coordinate extent.  Here we assume 1 pixel = 1 unit.\n",
    "    ypixels, xpixels = bg_img.shape[:2]\n",
    "    extent = [0, xpixels, 0, ypixels]   # (xmin, xmax, ymin, ymax)\n",
    "\n",
    "    # Prepare colour map\n",
    "    track_ids = df['TRACK_ID'].unique()\n",
    "    colours   = {tid: plt.cm.tab20(i % 20) for i, tid in enumerate(track_ids)}\n",
    "\n",
    "    timestamps = np.sort(df['TIMESTAMP'].unique())\n",
    "    if max_frames is not None:\n",
    "        timestamps = timestamps[:max_frames]\n",
    "    grouped = df.groupby('TIMESTAMP')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(bg_img, extent=extent, cmap='gray', origin='lower', zorder=0)\n",
    "\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        ax.imshow(bg_img, extent=extent, cmap='gray', origin='lower', zorder=0)\n",
    "        ax.set_xlim(extent[0], extent[1])\n",
    "        ax.set_ylim(extent[2], extent[3])\n",
    "        ax.set_aspect('equal')\n",
    "        return []\n",
    "\n",
    "    def update(frame_idx):\n",
    "        ts = timestamps[frame_idx]\n",
    "        ax.clear()\n",
    "        ax.imshow(bg_img, extent=extent, cmap='gray', origin='lower', zorder=0)\n",
    "        ax.set_xlim(extent[0], extent[1])\n",
    "        ax.set_ylim(extent[2], extent[3])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(f\"t = {ts:.2f}s\") \n",
    "        ax.axis('off')\n",
    "\n",
    "        if ts not in grouped.groups:\n",
    "            return []\n",
    "\n",
    "        frame_df = grouped.get_group(ts)\n",
    "        for _, row in frame_df.iterrows():\n",
    "            x, y   = float(row['X']), float(row['Y'])\n",
    "            tid    = row['TRACK_ID']\n",
    "            yaw_deg= float(row['yaw'])\n",
    "            speed  = float(row['speed'])\n",
    "            colour = colours.get(tid, 'black')\n",
    "\n",
    "            # Rectangle (car)\n",
    "            length, width = 4, 2\n",
    "            dx, dy        = -length/2, -width/2\n",
    "            rect = plt.Rectangle((x+dx, y+dy), length, width,\n",
    "                                 color=colour, alpha=0.8, zorder=2)\n",
    "            rot  = np.deg2rad(-(yaw_deg+90))          # negative for x-axis right-hand\n",
    "            transf = (plt.matplotlib.transforms.Affine2D()\n",
    "                      .rotate_around(x, y, rot) + ax.transData)\n",
    "            rect.set_transform(transf)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            # Velocity arrow\n",
    "            arrow_len = min(speed*0.4, 10)\n",
    "            vx = arrow_len * np.cos(np.deg2rad(yaw_deg+90))\n",
    "            vy = arrow_len * np.sin(np.deg2rad(yaw_deg+90))\n",
    "            ax.arrow(x, y, -vx, vy,\n",
    "                     head_width=0.7, head_length=1.2,\n",
    "                     fc='k', ec='k', zorder=3)\n",
    "\n",
    "        return []\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(timestamps),\n",
    "                                  init_func=init, interval=interval_ms, blit=False)\n",
    "    ani.save(out_mp4, writer='ffmpeg', fps=1000//interval_ms)\n",
    "    print(f\"Saved → {out_mp4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb12c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GNN_mtl_gnn(\n",
      "  (conv1): GraphConv(128, 128)\n",
      "  (conv2): GraphConv(128, 128)\n",
      "  (linear1): Linear(in_features=5, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear5): Linear(in_features=128, out_features=60, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 3/3 [00:16<00:00,  5.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "batch_size = 8000\n",
    "train_folder = \"csv/train_pre_1k_simple_separate_10m\"\n",
    "val_folder = \"csv/val_pre_1k_simple_separate_10m\"\n",
    "model_path = f\"trained_params_archive/sumo_with_mpc_online_control/model_rot_gnn_mtl_np_sumo_0911_e3_1930.pth\"\n",
    "inter_map = \"simple_separate_10m\"\n",
    "bg_img_path = f\"map_binary_images/{inter_map}_binary.png\"\n",
    "out_mp4 = f\"inference_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{inter_map}.mp4\"\n",
    "\n",
    "val_dataset = CarDataset(preprocess_folder=val_folder, mlp=False, mpc_aug=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "mlp = False\n",
    "collision_penalty = False\n",
    "model = GNN_mtl_mlp(hidden_channels=128).to(device) if mlp else GNN_mtl_gnn(hidden_channels=128)\n",
    "print(model)\n",
    "\n",
    "df_pred = run_inference(model_path, val_loader, mlp=mlp, device=device)\n",
    "visualise(df_pred, bg_img_path=bg_img_path, out_mp4=out_mp4, \n",
    "           interval_ms=100, max_frames=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
